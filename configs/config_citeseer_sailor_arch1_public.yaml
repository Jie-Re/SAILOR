activation: elu
alpha: 0.027825594022071243
arch: 1
augmentor:
  _lr: 0.0001
  hidden: 64
  lr: 0.0001
  n_layers: 1
  weight_decay: 0.0005
  optimizer: Adam
batch: 0
batch_size: 0
beta: 0.016681005372000592
dataset: Citeseer
degthres: 0
drop_prt: 0.6401407873062461
dropout: 0.5
epoch: 2000
eta: 0.21544346900318834
evaluate_mode: 0
gnn:
  hidden: 64
  lr: 0.001
  n_layers: 1
  norm_type: None
  weight_decay: 0.0005
  optimizer: Adam
n_trials: 100
patience: 200
split_type: public
temperature: 1
theta: 0.21544346900318834
use_lcc: 0
use_undirected: true
verbose: 0
visualize: 0
with_bias: 1
with_decay: 1
with_gpu: 1
