activation: elu
alpha: 1.0
arch: 2
augmentor:
  _lr: 0.0005
  hidden: 64
  lr: 0.1
  n_layers: 1
  optimizer: Adam
  weight_decay: 0.0005
batch: 0
batch_size: 0
beta: 1.0
dataset: Pubmed
degthres: 0
drop_prt: 0.3763908980400059
dropout: 0.5
epoch: 2000
eta: 0.21544346900318834
evaluate_mode: 1
gnn:
  hidden: 64
  lr: 0.01
  n_layers: 1
  norm_type: none
  optimizer: Adam
  weight_decay: 0.0005
n_trials: 100
patience: 200
split_type: tail
temperature: 1.603671511566729
theta: 0.046415888336127774
use_lcc: true
use_undirected: true
verbose: 0
visualize: 0
with_bias: 1
with_decay: 1
with_gpu: 1
